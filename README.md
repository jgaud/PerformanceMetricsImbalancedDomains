## An Analysis of Performance Metrics for Imbalanced Classification - DS 2021

This repository contains all the code used in the empirical tests conducted in the paper *"An Analysis of Performance Metrics in Imbalanced Classification"* [1].

This repository is organized as follows:

* **PerformanceMetricsImbalancedDomains.ipynb** file - contains all the code for reproducing the experiments presented in the paper;
* **Data** folder - contains the data sets used in the experiments carried out, taken from the KEEL repository [2];

### Requirements
The experiments were implemented in Python within the Jupyter Notebook environment. The code and results can be seen by opening the PerformanceMetricsImbalancedDomains.ipynb notebook.

If you want to replicate the experiments by yourself, a working installation of Python (https://www.python.org/) and Jupyter Notebook (https://jupyter.org/) are required.

Furthermore, the following Python packages are required:

- Pandas (https://pypi.org/project/pandas/)
- Numpy (https://pypi.org/project/numpy/)
- Matplotlib (https://pypi.org/project/matplotlib/)
- Krippendorff (https://pypi.org/project/krippendorff/)
- Scikit-Learn (https://pypi.org/project/scikit-learn/)
- Pyprg (https://pypi.org/project/pyprg/)

### References
[1] Gaudreault JG., Branco P., Gama J. (2021) An Analysis of Performance Metrics for Imbalanced Classification. In: Soares C., Torgo L. (eds) Discovery Science. DS 2021. Lecture Notes in Computer Science, vol 12986. Springer, Cham. https://doi-org.proxy.bib.uottawa.ca/10.1007/978-3-030-88942-5_6

[2] Alcalá-Fdez, J., Fernandez, A., Luengo, J., Derrac J., García S., Sánchez L., Herrera, F. (2011) KEEL Data-Mining Software Tool: Data Set Repository, Integration of Algorithms and Experimental Analysis Framework. Journal of Multiple-Valued Logic and Soft Computing.
